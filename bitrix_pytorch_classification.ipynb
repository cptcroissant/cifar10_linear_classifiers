{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добрый день. \n",
    "Это вторая часть задания по создания линейных классификаторов.\n",
    "\n",
    "В примере будет использована библиотека pytorch. \n",
    "В качестве модели выступает, как и в первой части, логистическая регрессия.   \n",
    "В основе работы лежит решение задачи многоклассовой классификации. Градиент ошибки вычислияется с помощью cross_entropy. \n",
    "Классификатор использует архитектуру нейронной сети с одним линейным слоем. Обратное распространение ошибки и обновление весов осуществляются в автоматическом режиме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных и библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем возможность стабильных репродуктивных результатов рерана тетрадки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для нормализации изображений рассчитаем среднее и среднеквадратичное отклонение для каждого из трех цветновых слоев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средние значения: [0.49139968 0.48215841 0.44653091]\n",
      "Отклонения: [0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "ROOT = r'F:\\\\temp_pics\\\\cifar'\n",
    "\n",
    "train_data = datasets.CIFAR10(root = ROOT, \n",
    "                              train = True, \n",
    "                              download = False)\n",
    "\n",
    "means = train_data.data.mean(axis = (0,1,2)) / 255\n",
    "stds = train_data.data.std(axis = (0,1,2)) / 255\n",
    "\n",
    "print(f'Средние значения: {means}')\n",
    "print(f'Отклонения: {stds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем трансформер, который преобразует исходные изображения для дальнейшей работы модели. Процесс изменения исходных фоторгафий называется аугментация.  \n",
    "В тестовую выборку добавим случайный поворот изображений на 5 градусов, отражение изображий по горизонтали, случайный кроп изображений. Аугментация поможет модели обучиться на большем разнообразии данных без добавления в датасет новых реальных фотографий.\n",
    "После изменений изображений, трансформер преобразует массивы данных в тензоры и нормализует их для подачи на вход модели.  \n",
    "\n",
    "Аугментация проводится только на обучающих данных. Искажение тестовых данных может испортить валидацию модели.\n",
    "  \n",
    "*При реране ноутбука на локальной машине - пожалуйста, скачайте архив [cifar_10](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz) в любую папку. Далее - измените путь к данным в ячейке ниже.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(32, padding = 2),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = means, \n",
    "                                                std = stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = means, \n",
    "                                                std = stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные и прогоняем через описанные выше трансформеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR10(ROOT, \n",
    "                              train = True, \n",
    "                              download = False, \n",
    "                              transform = train_transforms)\n",
    "\n",
    "test_data = datasets.CIFAR10(ROOT, \n",
    "                             train = False, \n",
    "                             download = False, \n",
    "                             transform = test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вариативности проверки результатов работы модели создадим валидационный датасет.  \n",
    "Применяем к нему трансформацию тестового датасета. Команда deepcopy() позволит избежать изменений в структуре valid_data, которая не подвергалась изменениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data, \n",
    "                                           [n_train_examples, n_valid_examples])  \n",
    "\n",
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные разделены на 3 сета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочный датасет: 45000\n",
      "Валидационный сет: 5000\n",
      "Тестовый сет: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'Тренировочный датасет: {len(train_data)}')\n",
    "print(f'Валидационный сет: {len(valid_data)}')\n",
    "print(f'Тестовый сет: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения модели необходимо создать итератор батчей. Батчи - небольшие наборы данных, несут две важные функции. Во-первых, обучение по частям позволяет занимать в памяти вычислительной машины меньше места, чем целый набор данных. Во-вторых, обучение на батчах позволяет усреднять ошибку и предсказания модели для различных классов. Так мы получаем более стабильный и качественный результат.  \n",
    "\n",
    "В данном примере я использую размер батча = 64 изображениям. Можно брать бОльший размер, который увеличит скорость обучения. Но текущая конфигурация локальной машины позволяет мне комфортно работать именно с таким размером выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание модели  \n",
    "\n",
    "Цель задания - написать любой линейный классификатор на pytorch. Предлагаю создать, как и в случае с numpy, логистическую регрессию и посмотреть, какой результат нам покажет эта модель.  \n",
    "\n",
    "Строим нейросеть, как бы серьезно это не звучало, с одним линейным слоем. В данном примере не используются свертки и сложные предобученные архитектуры. Интересно именно сравнить простые решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(3*32*32, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # этот шаг необходим для перевода трехмерного изображения о двумерный массив для подачи на линейный слой\n",
    "        x = x.view(x.shape[0], -1) \n",
    "        # уже обычный подсчет весов логистической регрессии\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из гиперпараметров передадим модели только размер выходного тензора. Решая задачу мультиклассовой классификации мы находим принадлежность изображения к одному из них. Тензор длинной 10 будет содержать вероятностное значение для каждого из десяти классов - какое изображение перед нами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 10\n",
    "\n",
    "classifier_pytorch = LogisticRegression(OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на количество параметров нашей логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 30,730 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(classifier_pytorch):\n",
    "    return sum(p.numel() for p in classifier_pytorch.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(classifier_pytorch):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличии от простых нейросетей с несколькими слоями и миллионом параметров в базе, наша малютка имеет всего лишь 31 тысячу параметров.   \n",
    "\n",
    "В качестве функции оптимизации исользуем алгоритм Adam. За функцию потерь, как и в случае с классификатором на numpy, отвечает cross-entropy. Единственное отличие - в pytorch их не надо прописывать вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(classifier_pytorch.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем возможность обучения модели на GPU и передаем в память видеокарты модель и функцию потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "classifier_pytorch = classifier_pytorch.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию подсчета accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем функции обучения и тестирования модели.  \n",
    "\n",
    "Переводим модель в состояние train().  \n",
    "Выбираем изображения для батча.  \n",
    "Обнуляем градиент предыдущего батча.\n",
    "Получаем предикты модели на данных батча.  \n",
    "Рассчитываем величину ошибки между предиктами и реальными значениями.  \n",
    "Смотрим на accuracy между предиктами и реальными лейблами.  \n",
    "Рассчитываем градиенты параметров.  \n",
    "Обновлаяем параметры командой step().  \n",
    "Обновляем метрики loss эпохи и accuracy эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred = model(x)\n",
    "      \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки работы модели создаем функцию evaluate()\n",
    "\n",
    "Переводим модель в состояние eval()  \n",
    "Функция torch.no_grad() отключает вычисления градиента и ошибки. На этом этапе нам не нужно совершать обратные преобразования.  \n",
    "Увеличиваем скорость работы и снижаем использование памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем функию подсчета времени эпохи обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем логистическую регрессию на пяти эпохах. В черновых версиях работы я довел обучение до 50 эпох, улучшения метрик нет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 2.079 | Train Acc: 29.95%\n",
      "\t Val. Loss: 2.059 |  Val. Acc: 32.54%\n",
      "Epoch: 02 | Epoch Time: 0m 32s\n",
      "\tTrain Loss: 2.063 | Train Acc: 31.27%\n",
      "\t Val. Loss: 1.978 |  Val. Acc: 34.93%\n",
      "Epoch: 03 | Epoch Time: 0m 32s\n",
      "\tTrain Loss: 2.045 | Train Acc: 32.02%\n",
      "\t Val. Loss: 2.000 |  Val. Acc: 33.43%\n",
      "Epoch: 04 | Epoch Time: 0m 34s\n",
      "\tTrain Loss: 2.047 | Train Acc: 32.07%\n",
      "\t Val. Loss: 2.030 |  Val. Acc: 35.21%\n",
      "Epoch: 05 | Epoch Time: 0m 32s\n",
      "\tTrain Loss: 2.050 | Train Acc: 32.10%\n",
      "\t Val. Loss: 2.082 |  Val. Acc: 33.03%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc = train(classifier_pytorch, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(classifier_pytorch, valid_iterator, criterion, device)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        # чтобы сохранить обученную модель с весами, раскомментируйте строку ниже и укажите путь сохранения.\n",
    "        #torch.save(model.state_dict(), 'path\\\\awesome_logistic_regression.pt')\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим работу модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.068 | Test Acc: 32.63%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(classifier_pytorch, test_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Невысокая точность предсказаний. Результаты близки к значениям sklearn и классификатору numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка работы модели  \n",
    "\n",
    "Создадим функцию для предсказания массивов изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim = -1)\n",
    "            top_pred = y_prob.argmax(1, keepdim = True)\n",
    "\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    probs = torch.cat(probs, dim = 0)\n",
    "    pred_labels = torch.argmax(probs, 1)\n",
    "    \n",
    "    return labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, preds = get_predictions(classifier_pytorch, test_iterator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3117884366830577"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true, preds, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим f1 score на предиктах модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data):\n",
    "    \n",
    "    true, preds = get_predictions(classifier_pytorch, data, device)\n",
    "    score = f1_score(true, preds, average='macro')\n",
    "    class_report = classification_report(true, preds)\n",
    "    \n",
    "    print('f1-macro скор модели =', np.round(score, 4))\n",
    "    print()\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro скор модели = 0.3004\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.24      0.26      4501\n",
      "           1       0.36      0.46      0.41      4495\n",
      "           2       0.21      0.28      0.24      4485\n",
      "           3       0.23      0.22      0.23      4518\n",
      "           4       0.29      0.22      0.25      4458\n",
      "           5       0.23      0.18      0.20      4533\n",
      "           6       0.35      0.26      0.30      4536\n",
      "           7       0.33      0.38      0.35      4502\n",
      "           8       0.37      0.46      0.41      4485\n",
      "           9       0.37      0.34      0.35      4487\n",
      "\n",
      "    accuracy                           0.30     45000\n",
      "   macro avg       0.30      0.30      0.30     45000\n",
      "weighted avg       0.30      0.30      0.30     45000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro скор модели = 0.315\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.22      0.27       499\n",
      "           1       0.41      0.43      0.42       505\n",
      "           2       0.22      0.25      0.23       515\n",
      "           3       0.24      0.16      0.19       482\n",
      "           4       0.35      0.27      0.31       542\n",
      "           5       0.34      0.14      0.20       467\n",
      "           6       0.36      0.31      0.33       464\n",
      "           7       0.37      0.41      0.39       498\n",
      "           8       0.33      0.57      0.42       515\n",
      "           9       0.33      0.50      0.40       513\n",
      "\n",
      "    accuracy                           0.33      5000\n",
      "   macro avg       0.33      0.33      0.31      5000\n",
      "weighted avg       0.33      0.33      0.32      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro скор модели = 0.3118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.19      0.23      1000\n",
      "           1       0.43      0.43      0.43      1000\n",
      "           2       0.22      0.26      0.24      1000\n",
      "           3       0.27      0.17      0.21      1000\n",
      "           4       0.29      0.27      0.28      1000\n",
      "           5       0.29      0.12      0.17      1000\n",
      "           6       0.39      0.30      0.34      1000\n",
      "           7       0.36      0.42      0.39      1000\n",
      "           8       0.32      0.59      0.42      1000\n",
      "           9       0.35      0.52      0.42      1000\n",
      "\n",
      "    accuracy                           0.33     10000\n",
      "   macro avg       0.32      0.33      0.31     10000\n",
      "weighted avg       0.32      0.33      0.31     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обновим табличку из первого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['numpy', 'sklearn', 'pytorch']\n",
    "time = [15.7, 10.1, 118.]\n",
    "train_score = [0.446, 0.582, 0.299]\n",
    "valid_score = [0.311, 0.311, 0.315]\n",
    "test_score = [0.300, 0.315, 0.312]\n",
    "\n",
    "dict_ = {'algorithm':models,\n",
    "         'training time':time, \n",
    "         'f1_train':train_score,\n",
    "         'f1_valid':valid_score,\n",
    "         'f1_test':test_score\n",
    "        }\n",
    "\n",
    "result = pd.DataFrame(data=dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>training time</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_valid</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numpy</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sklearn</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm  training time  f1_train  f1_valid  f1_test\n",
       "0     numpy           15.7     0.446     0.311    0.300\n",
       "1   sklearn           10.1     0.582     0.311    0.315\n",
       "2   pytorch          118.0     0.299     0.315    0.312"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модели нет переобучения! Однако заметна слабая недообученность. \n",
    "Валидационную и тестовую выборки модель предсказывает на уровне numpy и коробочного решения. Однако, очень сильно проигрывает по времени.  \n",
    "Анализ classification report показал, что модель лучше угадывает те же классы, что и решения из предыдущей работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод  \n",
    "\n",
    "В данной тетради представлена работа простой мультиклассовой логистической регрессии, написанной на pytorch. Обучающие и тестовые данные являются частью набора Cifar10.   \n",
    "Градиент ошибки рассчитывается с помощью softmax и cross-entropy.  \n",
    "\n",
    "Написанная \"нейросеть\" содержит 1 линейный слой. На выходе модели получаем числовые значения классов. Прогоняем их через softmax функцию для расчета вероятности принадлежности к классу.  \n",
    "\n",
    "Модель показала значения качества предсказий близкие к модели с архитектурой на numpy и решением sklearn. Единственное, в чем сильно проигрывает получанный классификатор - время обучения и предсказания.  \n",
    "\n",
    "Улучшить качество модели можно изменением архитектуры и использовании моделей с предобученными параметрами."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
